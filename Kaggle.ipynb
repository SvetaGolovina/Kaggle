{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Считывание данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', index_col='id')\n",
    "test = pd.read_csv('test.csv', index_col='id')\n",
    "submission = pd.read_csv('sample_submission.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train.pop('target')\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, train_size=0.60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По сравнению с другими классическими методами Random Forest Regressor показал наилучший результат. Дополнительно настроив параметры, получилось добиться ошибки=0.70395.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.70395\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Regressor\n",
    "model_rand_forest = RandomForestRegressor(n_estimators=140, max_features=4, n_jobs=-1, min_samples_leaf=15, random_state = 15)\n",
    "model_rand_forest.fit(X_train, y_train)\n",
    "y_rand_forest = model_rand_forest.predict(X_test)\n",
    "score_rand_forest = mean_squared_error(y_test, y_rand_forest, squared=False)\n",
    "print(f'{score_rand_forest:0.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Улучшаем результат, используя градиентный бустинг на деревьях.\n",
    "Взяв за основу параметры, полученные из модели Random Forest Regressor, анализируем остальние. Получаем ошибку 0.69991"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69991\n"
     ]
    }
   ],
   "source": [
    "#xgboost\n",
    "model = xgb.XGBRegressor(colsample_bytree=0.7, learning_rate=0.1,max_depth=8, min_child_weight=310, n_estimators=160,n_jobs=-1, random_state=15, verbosity=0)\n",
    "model.fit(X_train, y_train)\n",
    "y = model.predict(X_test)\n",
    "score = mean_squared_error(y_test, y, squared=False)\n",
    "print(f'{score:0.5f}')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение на кросс-валидации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы точнее настроить модель, используем кросс-валидацию.\n",
    "\n",
    "Для начала подготовим данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', index_col='id')\n",
    "test = pd.read_csv('test.csv', index_col='id')\n",
    "target = train['target']\n",
    "\n",
    "features = [f'cont{x}'for x in range(1,15)]\n",
    "\n",
    "train_data = train.drop(columns=['target'])\n",
    "test_data = test\n",
    "\n",
    "#Нормализация\n",
    "train_data = train_data / train_data.aggregate(\"max\")\n",
    "test_data = test_data / test_data.aggregate(\"max\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Param - подобранные на предыдущем этапе наилучше параметры.\n",
    "\n",
    "Получаем среднюю ошибку 0.6992320437452879"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.6989296642150992\n",
      "2 0.698089382035287\n",
      "3 0.6981242224152149\n",
      "4 0.7024195387631149\n",
      "5 0.6985974112977235\n",
      "mean MSE for all the folds is 0.6992320437452879\n"
     ]
    }
   ],
   "source": [
    "Param = {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 310,'n_estimators': 160, 'n_jobs': -1, 'random_state': 15, 'verbosity': 0}\n",
    "train0 = train_data\n",
    "test0 = test_data\n",
    "\n",
    "preds = np.zeros(test0.shape[0])\n",
    "mse=[]\n",
    "k=0\n",
    "kf = KFold(n_splits=5,random_state=15,shuffle=True)\n",
    "\n",
    "for train_idx, test_idx in kf.split(train0[features],target):\n",
    "    X_tr,X_val=train0[features].iloc[train_idx],train0[features].iloc[test_idx]\n",
    "    y_tr,y_val=target.iloc[train_idx],target.iloc[test_idx]\n",
    "    \n",
    "    model = xgb.XGBRegressor(**Param)\n",
    "    model.fit(X_tr,y_tr,eval_set=[(X_val,y_val)],early_stopping_rounds=100,verbose=False)\n",
    "    \n",
    "    preds+=model.predict(test0[features])/kf.n_splits\n",
    "    mse.append(mean_squared_error(y_val, model.predict(X_val), squared=False))\n",
    "    print(k+1,mse[k])\n",
    "    k+=1\n",
    "print(f\"mean MSE for all the folds is {np.mean(mse)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'] = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "0         7.879364\n",
       "2         7.862628\n",
       "6         7.881279\n",
       "7         8.064296\n",
       "10        8.203677\n",
       "            ...   \n",
       "499984    8.166514\n",
       "499985    8.191584\n",
       "499987    8.098135\n",
       "499988    8.107488\n",
       "499990    7.946080\n",
       "Name: target, Length: 200000, dtype: float32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('res.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
